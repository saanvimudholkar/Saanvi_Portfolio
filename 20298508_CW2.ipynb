{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab32288",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392700f",
   "metadata": {},
   "source": [
    "The given conditions of the question are :\n",
    "$$f_X(x)=\\frac{p}{\\sqrt{2\\pi \\sigma_1^2}}\\exp\\left(-\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}\\right)+\\frac{1-p}{\\sqrt{2\\pi \\sigma_2^2}}\\exp\\left(-\\frac{(x-\\mu_2)^2}{2\\sigma_2^2}\\right)$$\n",
    "\n",
    "$$p = 0.88, \\mu_1 = 3.79,\\mu_2 = 32.64, \\sigma_1 = 8.08, \\sigma_2 = 7.39 $$\n",
    "\n",
    "$$ stepsize =0.002, \\epsilon = 1/10^5, iterations = 10000$$\n",
    "\n",
    "\n",
    "From then given pdf and the corresponding log-likelihood, we get the following gradient:\n",
    "\n",
    "$$\\begin{align}\n",
    "   \\triangledown f(x)\n",
    "      =   \n",
    "    \\begin{bmatrix}\n",
    "           \\sum_{i=1}^n \\frac{1}{f_X(x_i)}[\\frac{1}{\\sqrt{2\\pi \\sigma_1^2}}\\exp\\left(-\\frac{(x_i-\\mu_1)^2}{2\\sigma_1^2}\\right) - \\frac{1}{\\sqrt{2\\pi \\sigma_2^2}}\\exp\\left(-\\frac{(x_i-\\mu_2)^2}{2\\sigma_2^2}\\right)]\\\\\n",
    "           \\sum_{i=1}^n \\frac{1}{f_X(x_i)}\\frac{p}{\\sqrt{2\\pi \\sigma_1^2}}\\exp\\left(-\\frac{(x_i-\\mu_1)^2}{2\\sigma_1^2}\\right)\\left(\\frac{x_i-\\mu_1}{\\sigma_1^2}\\right)\\\\\n",
    "           \\sum_{i=1}^n \\frac{1}{f_X(x_i)}\\frac{1-p}{\\sqrt{2\\pi \\sigma_2^2}}\\exp\\left(-\\frac{(x_i-\\mu_2)^2}{2\\sigma_2^2}\\right)\\left(\\frac{x_i-\\mu_2}{\\sigma_2^2}\\right)\\\\\n",
    "           \\sum_{i=1}^n \\frac{1}{f_X(x_i)}\\frac{p}{\\sqrt{2\\pi\\sigma_1^2}}\\exp\\left(-\\frac{(x_i-\\mu_1)^2}{2\\sigma_1^2}\\right)\\left(\\frac{(x_i-\\mu_1)^2-\\sigma_1^2}{|\\sigma_1^3|}\\right)\\\\\n",
    "           \\sum_{i=1}^n \\frac{1}{f_X(x_i)}\\frac{1-p}{\\sqrt{2\\pi\\sigma_2^2}}\\exp\\left(-\\frac{(x_i-\\mu_2)^2}{2\\sigma_2^2}\\right)\\left(\\frac{(x_i-\\mu_2)^2-\\sigma_2^2}{|\\sigma_2^3|}\\right)\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$$\n",
    "  \n",
    "First we define all the functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858a121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('/Users/saanvimudholkar/Desktop/data.csv', header=None)\n",
    "M = data.values.tolist()\n",
    "X = []\n",
    "for i in range(0,200):\n",
    "    X.append(M[i][0])\n",
    "def normal(x,mu,sigma):\n",
    "    return (1/np.sqrt(2*np.pi*sigma**2))*np.exp((-(x-mu)**2)/(2*sigma**2))\n",
    "\n",
    "def f(x,p,mu1,mu2,sigma1,sigma2):\n",
    "    return p*normal(x,mu1,sigma1)+(1-p)*normal(x,mu2,sigma2)\n",
    "\n",
    "def likelihood(x,p,mu1,mu2,sigma1,sigma2):\n",
    "    total=1\n",
    "    for i in range(0,len(X)):\n",
    "        total = total*f(X[i],p,mu1,mu2,sigma1,sigma2)\n",
    "        print(total)\n",
    "    return total\n",
    "\n",
    "def loglikelihood(x,p,mu1,mu2,sigma1,sigma2):\n",
    "    total=0\n",
    "    for i in range(0,len(X)):\n",
    "        total=total+np.log(f(X[i],p,mu1,mu2,sigma1,sigma2))\n",
    "    return total\n",
    "    \n",
    "def partial_p(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    total = 0\n",
    "    for i in range(0,len(X)):\n",
    "        total = total+((1/f(X[i],p,mu1,mu2,sigma1,sigma2))*(normal(X[i],mu1,sigma1)-normal(X[i],mu2,sigma2)))\n",
    "    return total\n",
    "\n",
    "def partial_mu1(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    total = 0\n",
    "    for i in range(0,len(X)):\n",
    "        total = total+((1/f(X[i],p,mu1,mu2,sigma1,sigma2))*p*normal(X[i],mu1,sigma1)*((X[i]-mu1)/sigma1**2))\n",
    "    return total\n",
    "\n",
    "def partial_mu2(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    total = 0\n",
    "    for i in range(0,len(X)):\n",
    "        total = total+((1/f(X[i],p,mu1,mu2,sigma1,sigma2))*(1-p)*normal(X[i],mu2,sigma2)*((X[i]-mu2)/sigma2**2))\n",
    "    return total\n",
    "\n",
    "def partial_sigma1(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    total = 0\n",
    "    for i in range(0,len(X)):\n",
    "        total = total+((1/f(X[i],p,mu1,mu2,sigma1,sigma2))*p*normal(X[i],mu1,sigma1)*((((X[i]-mu1)**2)-(sigma1**2))/np.abs(sigma1**3)))\n",
    "    return total\n",
    "\n",
    "def partial_sigma2(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    total = 0\n",
    "    for i in range(0,len(X)):\n",
    "        total = total+((1/f(X[i],p,mu1,mu2,sigma1,sigma2))*(1-p)*normal(X[i],mu2,sigma2)*((((X[i]-mu2)**2)-(sigma2**2))/np.abs(sigma2**3)))\n",
    "    return total\n",
    "\n",
    "def gradient(X,p,mu1,mu2,sigma1,sigma2):\n",
    "    return np.array([[partial_p(X,p,mu1,mu2,sigma1,sigma2),partial_mu1(X,p,mu1,mu2,sigma1,sigma2),partial_mu2(X,p,mu1,mu2,sigma1,sigma2),partial_sigma1(X,p,mu1,mu2,sigma1,sigma2),partial_sigma2(X,p,mu1,mu2,sigma1,sigma2)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec8eaa",
   "metadata": {},
   "source": [
    "#### Question 1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d2302",
   "metadata": {},
   "source": [
    "Using all the initial estimates, we find the maximum likelihood estimates of $ \\lambda = (p,\\mu_1,\\mu_2,\\sigma_1,\\sigma_2) $ using ordinary gradient descent method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47845c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 ; y =( 0.88 , 3.79 , 32.64 , 8.08 , 7.39 )\n",
      "Iteration  1 ; y =( 0.8935611823862428 , 3.790752894586099 , 32.63987413885199 , 8.082315202914131 , 7.3910077321416505 )\n",
      "Iteration  2 ; y =( 0.8597806350066038 , 3.791715319948181 , 32.63990416538742 , 8.085014123874863 , 7.391846474256193 )\n",
      "Iteration  3 ; y =( 0.9301049175578072 , 3.792180370916598 , 32.63956062688726 , 8.086759079447265 , 7.393101000822578 )\n",
      "Iteration  4 ; y =( 0.6944832211632178 , 3.793854718623239 , 32.64005472207549 , 8.090875930611434 , 7.393498674787138 )\n",
      "The maximum likelihood estimates of y = ( 1.014524035854293 , 3.792675626215902 , 32.63813413565857 , 8.089909034444203 , 7.39692229927185 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-785.700137266433"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.88\n",
    "mu1 = 3.79\n",
    "mu2 = 32.64\n",
    "sigma1 = 8.08\n",
    "sigma2 = 7.39\n",
    "\n",
    "for j in range(0,10000):\n",
    "    print('Iteration ',j,'; y =(',p,',', mu1,',',mu2,',',sigma1,',',sigma2,')')\n",
    "    a = p\n",
    "    b = mu1\n",
    "    c = mu2\n",
    "    d = sigma1\n",
    "    e = sigma2\n",
    "    p = a + 0.002*partial_p(X,a,b,c,d,e)\n",
    "    mu1 = b + 0.002*partial_mu1(X,a,b,c,d,e)\n",
    "    mu2 = c + 0.002*partial_mu2(X,a,b,c,d,e)\n",
    "    sigma1 = d + 0.002*partial_sigma1(X,a,b,c,d,e)\n",
    "    sigma2 = e + 0.002*partial_sigma2(X,a,b,c,d,e)\n",
    "    if np.linalg.norm(gradient(X,p,mu1,mu2,sigma1,sigma2))<=10**-5 or p<0 or p>1:\n",
    "        print('The maximum likelihood estimates of y = (',p,',', mu1,',',mu2,',',sigma1,',',sigma2,')')\n",
    "        break\n",
    "loglikelihood(X,a,b,c,d,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229de01e",
   "metadata": {},
   "source": [
    "#### Question 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26156e",
   "metadata": {},
   "source": [
    "Using all the initial estimates, we find the maximum likelihood estimates of $ \\lambda = (p,\\mu_1,\\mu_2,\\sigma_1,\\sigma_2) $ using gradient projection method by projecting estimate of p to the interval $[0,1]$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f4bed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  500 ; y =( 0.8641186356761509 , 4.7712160256014 , 27.14015430887643 , 9.526534175065848 , 16.729693040284662 )\n",
      "Iteration  1000 ; y =( 0.8364926959900572 , 3.9486599553341644 , 26.977724852672537 , 8.378893223916217 , 16.216491415244352 )\n",
      "The maximum likelihood estimates of y at 1330 is = ( 0.8310626273354524 , 3.7035837742088713 , 26.835515296952526 , 8.216631630758425 , 15.847350746279592 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-769.5181990801111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.88\n",
    "mu1 = 3.79\n",
    "mu2 = 32.64\n",
    "sigma1 = 8.08\n",
    "sigma2 = 7.39\n",
    "\n",
    "for j in range(1,10001):\n",
    "    a = p\n",
    "    b = mu1\n",
    "    c = mu2\n",
    "    d = sigma1\n",
    "    e = sigma2\n",
    "    p = p + 0.002*partial_p(X,a,b,c,d,e)\n",
    "    mu1 = mu1 + 0.002*partial_mu1(X,a,b,c,d,e)\n",
    "    mu2 = mu2 + 0.002*partial_mu2(X,a,b,c,d,e)\n",
    "    sigma1 = sigma1 + 0.002*partial_sigma1(X,a,b,c,d,e)\n",
    "    sigma2 = sigma2 + 0.002*partial_sigma2(X,a,b,c,d,e)\n",
    "    if j%500==0:\n",
    "        print('Iteration ',j,'; y =(',p,',', mu1,',',mu2,',',sigma1,',',sigma2,')') \n",
    "    if p<0:\n",
    "        p=0\n",
    "    elif p>1:\n",
    "        p =1\n",
    "    if np.linalg.norm(a-p)<=10**(-5):\n",
    "        print('The maximum likelihood estimates of y at',j,'is ='' (',p,',', mu1,',',mu2,',',sigma1,',',sigma2,')')\n",
    "        break\n",
    "\n",
    "loglikelihood(X,p,mu1,mu2,sigma1,sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e19da",
   "metadata": {},
   "source": [
    "The estimate of p seems to be slowly decreasing as the program runs. We can observe that the values of $ \\mu_1, \\mu_2 $ are smaller than the initial values whereas the values of $\\sigma_1, \\sigma_2$ are larger than the initial estimates. This indicates that the graph is spread wider and the height of the peaks is shorter. Further, the decrease in $\\mu_2$ and increase in $\\sigma_2$ is much higher than $\\mu_1, \\sigma_1$ thus, the $\\mu_2, \\sigma_2 $ peak will be wider and shorter as compared to $\\mu_1,\\sigma_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579242d",
   "metadata": {},
   "source": [
    "#### Question 1c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df681b",
   "metadata": {},
   "source": [
    "Using all the initial estimates, we find the maximum likelihood estimates of $ \\lambda = (p,\\mu_1,\\mu_2,\\sigma_1,\\sigma_2) $ using gradient projection method by projecting estimate of p to the interval $[0.1,0.9]$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0245f43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  500 ; y =( 0.8458549066794072 , 3.9391314254363317 , 32.569247407130156 , 8.32956048880279 , 7.777891032646901 )\n",
      "Iteration  1000 ; y =( 0.8423154465738639 , 3.9402027670971256 , 32.483679843888275 , 8.324967944149352 , 8.007038490660603 )\n",
      "Iteration  1500 ; y =( 0.8386500707201983 , 3.922336205807169 , 32.378980263538466 , 8.312540694492844 , 8.169449506793214 )\n",
      "Iteration  2000 ; y =( 0.8352370507138831 , 3.903755717221643 , 32.2649169897863 , 8.300307074819333 , 8.29592935727593 )\n",
      "Iteration  2500 ; y =( 0.8320334159241537 , 3.8861652147413133 , 32.14720539046695 , 8.288761148201717 , 8.401301997390046 )\n",
      "Iteration  3000 ; y =( 0.8289859973824691 , 3.869481532179545 , 32.02881492268164 , 8.277850086765204 , 8.49366267574765 )\n",
      "Iteration  3500 ; y =( 0.8260574522592197 , 3.8535163607034364 , 31.911209277983293 , 8.267492580325346 , 8.577720739633449 )\n",
      "Iteration  4000 ; y =( 0.8232217541853063 , 3.8381250527243513 , 31.79503516105767 , 8.257620517974619 , 8.65633075774875 )\n",
      "Iteration  4500 ; y =( 0.8204598338748005 , 3.823200261897734 , 31.68049354301101 , 8.248177330861475 , 8.73128118337762 )\n",
      "Iteration  5000 ; y =( 0.8177569996996088 , 3.8086590069707156 , 31.56754390495098 , 8.239114878561884 , 8.803727876605928 )\n",
      "Iteration  5500 ; y =( 0.8151014581659892 , 3.794434512866437 , 31.456018761595676 , 8.230391610138152 , 8.874442257619489 )\n",
      "Iteration  6000 ; y =( 0.8124834378457146 , 3.780471406132565 , 31.34568845293066 , 8.221971473896451 , 8.943957312141903 )\n",
      "Iteration  6500 ; y =( 0.8098946488187561 , 3.766722791875736 , 31.236297722896754 , 8.213823179304518 , 9.012655230654197 )\n",
      "Iteration  7000 ; y =( 0.8073279355077176 , 3.7531483875257043 , 31.12758607843179 , 8.205919631446562 , 9.080820837678687 )\n",
      "Iteration  7500 ; y =( 0.8047770453800576 , 3.7397132751393594 , 31.01929878209479 , 8.198237463665839 , 9.148674589646868 )\n",
      "Iteration  8000 ; y =( 0.8022364697816468 , 3.7263870338572542 , 30.911192457402883 , 8.190756637664986 , 9.216393189822142 )\n",
      "Iteration  8500 ; y =( 0.7997013314201108 , 3.713143117930829 , 30.80303763804638 , 8.183460097277479 , 9.284122605142827 )\n",
      "Iteration  9000 ; y =( 0.7971673031856836 , 3.6999584012416094 , 30.694619631185084 , 8.176333468267186 , 9.351986368624432 )\n",
      "Iteration  9500 ; y =( 0.7946305488152933 , 3.6868128398641873 , 30.58573849861568 , 8.16936479851252 , 9.42009092472935 )\n",
      "Iteration  10000 ; y =( 0.7920876793131169 , 3.673689221641811 , 30.476208623627592 , 8.16254433348619 , 9.488529099403332 )\n",
      "The algorithm does not converge after 10000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-770.5622003108757"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.88\n",
    "mu1 = 3.79\n",
    "mu2 = 32.64\n",
    "sigma1 = 8.08\n",
    "sigma2 = 7.39\n",
    "\n",
    "for j in range(1,10001):\n",
    "    a = p\n",
    "    b = mu1\n",
    "    c = mu2\n",
    "    d = sigma1\n",
    "    e = sigma2\n",
    "    p = a + 0.002*partial_p(X,a,b,c,d,e)\n",
    "    mu1 = b + 0.002*partial_mu1(X,a,b,c,d,e)\n",
    "    mu2 = c + 0.002*partial_mu2(X,a,b,c,d,e)\n",
    "    sigma1 = d + 0.002*partial_sigma1(X,a,b,c,d,e)\n",
    "    sigma2 = e + 0.002*partial_sigma2(X,a,b,c,d,e)\n",
    "    if j%500==0:\n",
    "        print('Iteration ',j,'; y =(',p,',', mu1,',',mu2,',',sigma1,',',sigma2,')') \n",
    "    if p<0.1:\n",
    "        p=0.1\n",
    "    elif p>0.9:\n",
    "        p =0.9\n",
    "    if np.linalg.norm(a-p)<=10**-5:\n",
    "        print('The maximum likelihood estimates of y at',j,'is ='' (', mu1,',',mu2,',',sigma1,',',sigma2,')')\n",
    "        break\n",
    "print('The algorithm does not converge after 10000 iterations')   \n",
    "\n",
    "loglikelihood(X,p,mu1,mu2,sigma1,sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5cb4e6",
   "metadata": {},
   "source": [
    "The algorithm does not converge after 10000 iterations which indicates that given the projection condition, the stepsize is too big for the value to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e7c07",
   "metadata": {},
   "source": [
    "#### Question 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ad144",
   "metadata": {},
   "source": [
    "Using all the initial estimates, we find the maximum likelihood estimates of $ \\lambda = (p,\\mu_1,\\mu_2,\\sigma_1,\\sigma_2) $ using gradient projection method by projecting estimate of p to the interval $[0.1,0.9]$ with stepsize = $0.001$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72356844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum likelihood estimates of y at 17 is = ( 3.7972374556662207 , 32.63931917923823 , 8.101040749857832 , 7.398537388967441 )\n",
      "The value of the loglikelihood function is: -767.742483870644\n"
     ]
    }
   ],
   "source": [
    "p = 0.88\n",
    "mu1 = 3.79\n",
    "mu2 = 32.64\n",
    "sigma1 = 8.08\n",
    "sigma2 = 7.39\n",
    "\n",
    "for j in range(0,10000):\n",
    "    a = p\n",
    "    b = mu1\n",
    "    c = mu2\n",
    "    d = sigma1\n",
    "    e = sigma2\n",
    "    p = a + 0.001*partial_p(X,a,b,c,d,e)\n",
    "    mu1 = b + 0.001*partial_mu1(X,a,b,c,d,e)\n",
    "    mu2 = c + 0.001*partial_mu2(X,a,b,c,d,e)\n",
    "    sigma1 = d + 0.001*partial_sigma1(X,a,b,c,d,e)\n",
    "    sigma2 = e + 0.001*partial_sigma2(X,a,b,c,d,e)\n",
    "    if p<0.1:\n",
    "        p=0.1\n",
    "    elif p>0.9:\n",
    "        p =0.9\n",
    "    if np.linalg.norm(a-p)<=10**-5:\n",
    "        print('The maximum likelihood estimates of y at',j,'is ='' (', mu1,',',mu2,',',sigma1,',',sigma2,')')\n",
    "        break\n",
    "        \n",
    "print('The value of the loglikelihood function is:', loglikelihood(X,p,mu1,mu2,sigma1,sigma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934aae68",
   "metadata": {},
   "source": [
    "On decreasing the stepsize, the code converges giving and MLE which is close to the value of $\\lambda$ obtained in $q1a$ which minor differences. Further on calculating the loglikehood of all cases, we see that the values are $value(q1d)>value(q1a)>value(q1b)>value(q1c) $ meaning, given the data set, the conditions and $q1d $ provides the most accurate answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156f2a3",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597aed6",
   "metadata": {},
   "source": [
    "#### Question 2a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee03d55",
   "metadata": {},
   "source": [
    "Let Type A = $ x $, Type B = $ y $ and Type C = $z$, thus from the given question we can formulate the problem as:\n",
    "\n",
    "$$ min\\ -150x-175y-218z\\\\ such\\ that\\ 6.5x+7.8y+9.2z<=120\\\\ x+y+z<=12\\\\ -45x-60y-75z<=-800\\\\ -x<=-2\\\\ -y<=-2 $$\n",
    "\n",
    "We can also frame the question in a linear problem as:\n",
    "\n",
    "$$ min\\ c^Tx\\\\ such\\ that\\ Ax<=b $$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{align}\n",
    "   A\n",
    "      =   \n",
    "    \\begin{bmatrix}\n",
    "           6.5&7.8&9.2\\\\\n",
    "           1&1&1\\\\\n",
    "           -45&-60&-75\\\\\n",
    "           -1&0&0\\\\\n",
    "           0&-1&0\\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$$\n",
    "  \n",
    "$$\\begin{align}\n",
    "   b\n",
    "      =   \n",
    "    \\begin{bmatrix}\n",
    "           120\\\\\n",
    "           12\\\\\n",
    "           -800\\\\\n",
    "           -2\\\\\n",
    "           -2\\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$$  \n",
    "  \n",
    "$$\\begin{align}\n",
    "   c\n",
    "      =   \n",
    "    \\begin{bmatrix}\n",
    "           -150\\\\\n",
    "           -175\\\\\n",
    "           -218\\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$$    \n",
    "\n",
    "From the given question we can formulate the linear programming problem as:\n",
    "\n",
    "Let $p=(x,y,z)^t$ and $\\lambda=(\\lambda_1,\\lambda_2,\\lambda_3, \\lambda_4, \\lambda_5)$\n",
    "\n",
    "$ L(p,\\lambda)=-150x-175y-218z+\\lambda_1(6.5x+7.8y+9.2z-120)+\\lambda_2(x+y+z-12)-\\lambda_3(45x+60y+75z-800)-\\lambda_4(x-2)-\\lambda_5(y-2) $\n",
    "\n",
    "OR\n",
    "\n",
    "$$ L(p,\\lambda) = (c^T+\\lambda^T A)x - \\lambda^T b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0db0e",
   "metadata": {},
   "source": [
    "#### Question 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d43a8",
   "metadata": {},
   "source": [
    "We can get the KKT conditions as follows:\n",
    "\n",
    "$$ dL(p,\\lambda)/dx=>-150+6.5\\lambda_1+\\lambda_2-45\\lambda_3-\\lambda_4=0\\\\ dL(p,\\lambda)/dy=>-175+7.8\\lambda_1+\\lambda_2-60\\lambda_3-\\lambda_5=0\\\\ dL(p,\\lambda)/dz=>-218+9.2\\lambda_1+\\lambda_2-75\\lambda_3=0$$\n",
    "\n",
    "The complimentary slackness conditions are as follows:\n",
    "\n",
    "$$ \\lambda_1(6.5x+7.8y+9.2z-120)=0\\\\ \\lambda_2(x+y+z-12)=0\\\\ \\lambda_3(-45x-60y-75z+800)=0\\\\ \\lambda_4(-x+2)=0\\\\ \\lambda_5(-y+2)=0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93120142",
   "metadata": {},
   "source": [
    "From the conditions, we consider the case $$ \\lambda_2=\\lambda_4=\\lambda_5 \\neq 0 $$ thus by complimentary slackness conditions we can say that:\n",
    "$$ x+y+z-12=0\\\\ -x+2=0\\\\ -y+2=0 $$\n",
    "Thus, $$x=2\\\\ y=2\\\\ z=8 $$\n",
    "Consider, $\\lambda_1=\\lambda_3 =0 $, thus $6.5x+7.8y+9.2z-120 \\neq 0$ and $-45x-60y-75z+800 \\neq 0$ respectively\n",
    "Further on substituting $x,y,z$ in the above equations, \n",
    "$$6.5x+7.8y+9.2z-120 => 102.2-120=> -17.8 \\neq 0 $$\n",
    "$$-45x-60y-75z+800 => -810+800 => -10 \\neq 0 $$\n",
    "Thus proving the above statement \n",
    "\n",
    "\n",
    "\n",
    "For optimality conditions, on substituting $\\lambda_1=\\lambda_3 =0 $ we get,\n",
    "$$ -150+\\lambda_2-\\lambda_4=0\\\\ -175+\\lambda_2-\\lambda_5=0\\\\ -218+\\lambda_2=0 $$\n",
    "\n",
    "Thus, $\\lambda_2=218, \\lambda_4=68, \\lambda_5=43$ which also satisfies the condition, $\\lambda_2=\\lambda_4=\\lambda_5 \\neq 0 $\n",
    "\n",
    "Lastly, as $ \\lambda_1,\\lambda_2,\\lambda_3,\\lambda_4,\\lambda_5>=0$, and satisfying the both optimality conditions and complimnetary slackness conditions, we can apply the Theorem: KKT Conditions for Convex Linearly Constrained Problems - Necessary and Sufficient Optimality Conditions, to say that \n",
    "$$p=(x,y,z)=(2,2,8)$$\n",
    "is an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c56b9",
   "metadata": {},
   "source": [
    "#### Question 2c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ffcd8",
   "metadata": {},
   "source": [
    "According to the dual objective function\n",
    "\n",
    "$$ q(\\lambda) = min L(x,\\lambda)\\\\= min (c^T+\\lambda^T A)x - \\lambda^T b\\\\= -\\lambda^T b $$ if $$c+A^T \\lambda>=0\\\\ -\\infty  otherwise $$\n",
    "\n",
    "Thus we can formulate the dual problem as:\n",
    "\n",
    "$$ max -\\lambda^T b\\\\= -120\\lambda_1-12\\lambda_2+800\\lambda_3+2\\lambda_4+2\\lambda_5 $$\n",
    "\n",
    "such that,\n",
    "\n",
    "$$6.5\\lambda_1+\\lambda_2-45\\lambda_3-\\lambda_4 = 150\\\\ 7.8\\lambda_1+\\lambda_2-60\\lambda_3-\\lambda_5 = 175\\\\ 9.2\\lambda_1+\\lambda_2-75\\lambda_3 = 218 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94c19a",
   "metadata": {},
   "source": [
    "#### Question 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6080a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  20000 ; y =  [[  0.        ]\n",
      " [176.82947536]\n",
      " [  0.        ]\n",
      " [ 51.50237315]\n",
      " [ 34.75268744]]\n",
      "Iteration  40000 ; y =  [[  0.        ]\n",
      " [213.01157484]\n",
      " [  0.        ]\n",
      " [ 65.92051966]\n",
      " [ 41.96455117]]\n",
      "Iteration  60000 ; y =  [[  0.        ]\n",
      " [214.958124  ]\n",
      " [  0.        ]\n",
      " [ 66.6961969 ]\n",
      " [ 42.35253991]]\n",
      "Iteration  80000 ; y =  [[  0.        ]\n",
      " [215.06284578]\n",
      " [  0.        ]\n",
      " [ 66.73792731]\n",
      " [ 42.3734132 ]]\n",
      "Iteration  100000 ; y =  [[  0.        ]\n",
      " [215.06847967]\n",
      " [  0.        ]\n",
      " [ 66.74017235]\n",
      " [ 42.37453615]]\n",
      "Iteration  120000 ; y =  [[  0.        ]\n",
      " [215.06878277]\n",
      " [  0.        ]\n",
      " [ 66.74029313]\n",
      " [ 42.37459657]]\n",
      "Iteration  140000 ; y =  [[  0.        ]\n",
      " [215.06879907]\n",
      " [  0.        ]\n",
      " [ 66.74029963]\n",
      " [ 42.37459982]]\n",
      "Iteration  160000 ; y =  [[  0.        ]\n",
      " [215.06879995]\n",
      " [  0.        ]\n",
      " [ 66.74029998]\n",
      " [ 42.37459999]]\n",
      "Iteration  180000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  200000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  220000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  240000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  260000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  280000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  300000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  320000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  340000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  360000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  380000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Iteration  400000 ; y =  [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n",
      "Value of lambda: [[  0.    ]\n",
      " [215.0688]\n",
      " [  0.    ]\n",
      " [ 66.7403]\n",
      " [ 42.3746]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[5],[5],[5],[5],[5]])\n",
    "t = 0.005\n",
    "A = np.array([[6.5, 1, -45,-1,0],[7.8,1,-60,0,-1],[9.2,1,-75,0,0]])\n",
    "c = np.array([[-120],[-12],[800],[2],[2]])\n",
    "b = np.array([[150],[175],[218]])\n",
    "grad = c\n",
    "for i in range(1,400001):\n",
    "    m = y + t*grad\n",
    "    y = m - (A.transpose()@(np.linalg.inv(A@A.transpose()))@((A@m)-b))\n",
    "    for j in range(0,5):\n",
    "        if y[j]<=0:\n",
    "            y[j]=0\n",
    "    if i%20000==0:\n",
    "        print('Iteration ',i,'; y = ', y)\n",
    "print('Value of lambda:',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98968f",
   "metadata": {},
   "source": [
    "The values of $\\lambda$ obtained in part d is slightly different from part b. For $\\lambda_2$ the difference is of 3 digits, for $\\lambda_4$ difference is of 2 digits and for $\\lambda_5$ difference is of 1 digit. For $\\lambda_1,\\lambda_3$ the values are the same which is 0.\n",
    "\n",
    "Thus, we do not get the same answer as 2b but close.\n",
    "\n",
    "Further, upon decreasing the stepsize, we get values closer to the answer in 2b. Thus, to improve the precision, we must decrease the stepsize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
